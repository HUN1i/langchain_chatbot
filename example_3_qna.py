"""
ì˜ˆì œ 3: ë¬¸ì„œ ê¸°ë°˜ Q&A ì±—ë´‡ (RAG)
====================================
ì‹¤í–‰: streamlit run example_3_qna.py
"""

import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

load_dotenv()

st.set_page_config(page_title="ë¬¸ì„œ Q&A", page_icon="ğŸ“š")
st.title("ğŸ“š ë¬¸ì„œ ê¸°ë°˜ Q&A ì±—ë´‡")
st.caption("ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤!")

model = ChatOpenAI(model="gpt-4.1-mini", temperature=0.3)

# ì˜ˆì œ ë¬¸ì„œ (ì‹¤ì œë¡œëŠ” PDF, TXT ë“±ì—ì„œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŒ)
sample_documents = [
    """
    Python ê¸°ì´ˆ
    - Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.
    - ë°°ìš°ê¸° ì‰½ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.
    - ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ì¸ê³µì§€ëŠ¥ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    - ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
    """,
    """
    Python ìë£Œêµ¬ì¡°
    - ë¦¬ìŠ¤íŠ¸(List): ìˆœì„œê°€ ìˆëŠ” ë³€ê²½ ê°€ëŠ¥í•œ ìë£Œêµ¬ì¡° [1, 2, 3]
    - íŠœí”Œ(Tuple): ìˆœì„œê°€ ìˆëŠ” ë³€ê²½ ë¶ˆê°€ëŠ¥í•œ ìë£Œêµ¬ì¡° (1, 2, 3)
    - ë”•ì…”ë„ˆë¦¬(Dictionary): í‚¤-ê°’ ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ ìë£Œêµ¬ì¡° {"key": "value"}
    - ì„¸íŠ¸(Set): ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ìë£Œêµ¬ì¡° {1, 2, 3}
    """,
    """
    Python í•¨ìˆ˜
    - def í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    - return ë¬¸ìœ¼ë¡œ ê°’ì„ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë§¤ê°œë³€ìˆ˜ì— ê¸°ë³¸ê°’ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ëŒë‹¤ í•¨ìˆ˜ë¡œ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ í•œ ì¤„ë¡œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì˜ˆì‹œ: lambda x: x + 1
    """
]

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    st.write("### ğŸ“„ í˜„ì¬ ë¬¸ì„œ")
    st.info(f"ì´ {len(sample_documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    st.divider()
    st.caption("ğŸ’¡ RAG (Retriever)ë¥¼ í™œìš©í•œ ì˜ˆì œì…ë‹ˆë‹¤!")

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
@st.cache_resource
def init_vectorstore():
    documents = [Document(page_content=doc) for doc in sample_documents]
    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20, separator="\n")
    split_docs = text_splitter.split_documents(documents)
    
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(
        documents=split_docs,
        embedding=embeddings,
        collection_name="python_docs"
    )
    return vectorstore

# ì´ˆê¸°í™”
with st.spinner("ë¬¸ì„œ ì¤€ë¹„ ì¤‘..."):
    vectorstore = init_vectorstore()

retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# RAG ì²´ì¸
template = """ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì •ë³´ê°€ ì—†ìœ¼ë©´ "ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""

prompt = ChatPromptTemplate.from_template(template)

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

# ë©”ì¸
st.write("### ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")
st.caption("ì˜ˆì‹œ: Pythonì€ ì–¸ì œ ë§Œë“¤ì–´ì¡Œì–´? / ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ëŠ”?")

question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

if st.button("ğŸ” ê²€ìƒ‰ ë° ë‹µë³€", type="primary"):
    if question:
        with st.spinner("ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            # ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
            relevant_docs = retriever.invoke(question)
            
            # ë‹µë³€ ìƒì„±
            answer = rag_chain.invoke(question)
            
            st.success("ë‹µë³€ ì™„ë£Œ!")
            st.write("### ğŸ“ ë‹µë³€:")
            st.info(answer)
            
            # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
            with st.expander("ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ë³´ê¸°"):
                for i, doc in enumerate(relevant_docs, 1):
                    st.write(f"**ë¬¸ì„œ {i}:**")
                    st.write(doc.page_content)
                    st.divider()
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")

